---
phase: 06-infrastructure-monitoring
plan: 05
type: execute
wave: 3
depends_on: ["06-03", "06-04"]
files_modified:
  - maguey-pass-lounge/supabase/migrations/20260131000000_alert_digest_system.sql
  - maguey-pass-lounge/supabase/functions/send-error-digest/index.ts
autonomous: false

must_haves:
  truths:
    - "Errors are aggregated in database before alerting"
    - "Similar errors are grouped by hash to prevent spam"
    - "Email digest sent every 15 minutes if errors exist"
    - "Owner receives actionable email with error summary"
    - "pg_cron job triggers digest edge function"
  artifacts:
    - path: "maguey-pass-lounge/supabase/migrations/20260131000000_alert_digest_system.sql"
      provides: "Alert digest table and aggregation function"
      contains: "CREATE TABLE alert_digest"
    - path: "maguey-pass-lounge/supabase/functions/send-error-digest/index.ts"
      provides: "Error digest email sender"
      exports: ["serve"]
  key_links:
    - from: "send-error-digest/index.ts"
      to: "alert_digest table"
      via: "SELECT unnotified errors"
      pattern: "from\\(['\"]alert_digest['\"]\\)"
    - from: "send-error-digest/index.ts"
      to: "Resend API"
      via: "send email"
      pattern: "resend\\.emails\\.send|api\\.resend\\.com"
    - from: "pg_cron"
      to: "send-error-digest/index.ts"
      via: "HTTP POST via pg_net"
      pattern: "cron\\.schedule"
---

<objective>
Create email alert system for aggregated error notifications to owner

Purpose: Alert owner to production issues without email spam
Output: Alert digest table, aggregation function, digest edge function, and pg_cron job
</objective>

<execution_context>
@/Users/luismiguel/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luismiguel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-infrastructure-monitoring/06-CONTEXT.md
@.planning/phases/06-infrastructure-monitoring/06-RESEARCH.md
@.planning/phases/06-infrastructure-monitoring/06-03-SUMMARY.md
@.planning/phases/06-infrastructure-monitoring/06-04-SUMMARY.md
@maguey-pass-lounge/supabase/functions/notify-payment-failure/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create alert_digest table and aggregation function</name>
  <files>maguey-pass-lounge/supabase/migrations/20260131000000_alert_digest_system.sql</files>
  <action>
Create migration for alert digest system (per RESEARCH.md):

```sql
-- Migration: Alert digest system for aggregated error notifications
-- Purpose: Aggregate errors before alerting to prevent email spam

-- ========================================
-- 1. Alert Digest Table
-- ========================================

CREATE TABLE IF NOT EXISTS alert_digest (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  error_type TEXT NOT NULL,
  error_hash TEXT NOT NULL, -- MD5 hash of error_type + message for grouping
  first_occurrence TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  last_occurrence TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  occurrence_count INTEGER NOT NULL DEFAULT 1,
  sample_error JSONB NOT NULL, -- First error details for context
  notified_at TIMESTAMPTZ, -- When digest email was sent
  resolved_at TIMESTAMPTZ, -- When issue was marked resolved
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),

  -- Unique constraint: one entry per error_hash per day (group by date)
  UNIQUE(error_hash, DATE(first_occurrence))
);

-- Index for fetching unnotified errors
CREATE INDEX idx_alert_digest_unnotified
  ON alert_digest (notified_at)
  WHERE notified_at IS NULL;

-- Index for dashboard queries
CREATE INDEX idx_alert_digest_recent
  ON alert_digest (last_occurrence DESC);

-- ========================================
-- 2. Aggregate Error Function
-- ========================================

-- Function to aggregate errors (called by edge functions)
CREATE OR REPLACE FUNCTION aggregate_error(
  p_error_type TEXT,
  p_error_message TEXT,
  p_error_details JSONB DEFAULT '{}'::JSONB
) RETURNS UUID
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  v_hash TEXT;
  v_id UUID;
BEGIN
  -- Create hash from error type and message for grouping
  v_hash := md5(p_error_type || ':' || COALESCE(p_error_message, 'unknown'));

  -- Upsert: insert new or update existing error entry
  INSERT INTO alert_digest (
    error_type,
    error_hash,
    sample_error,
    first_occurrence,
    last_occurrence,
    occurrence_count
  )
  VALUES (
    p_error_type,
    v_hash,
    jsonb_build_object(
      'message', p_error_message,
      'details', p_error_details,
      'timestamp', NOW()
    ),
    NOW(),
    NOW(),
    1
  )
  ON CONFLICT (error_hash, DATE(first_occurrence))
  DO UPDATE SET
    last_occurrence = NOW(),
    occurrence_count = alert_digest.occurrence_count + 1
  RETURNING id INTO v_id;

  RETURN v_id;
END;
$$;

-- ========================================
-- 3. RLS Policies
-- ========================================

ALTER TABLE alert_digest ENABLE ROW LEVEL SECURITY;

-- Authenticated users can view alerts (for dashboard)
CREATE POLICY "Authenticated users can view alerts"
  ON alert_digest
  FOR SELECT
  TO authenticated
  USING (true);

-- Authenticated users can mark alerts as resolved
CREATE POLICY "Authenticated users can update alerts"
  ON alert_digest
  FOR UPDATE
  TO authenticated
  USING (true)
  WITH CHECK (true);

-- Service role can insert and update (for edge functions)
CREATE POLICY "Service role can manage alerts"
  ON alert_digest
  FOR ALL
  TO service_role
  USING (true)
  WITH CHECK (true);

-- ========================================
-- 4. Comments
-- ========================================

COMMENT ON TABLE alert_digest IS 'Aggregated error log for digest notifications';
COMMENT ON COLUMN alert_digest.error_hash IS 'MD5 hash of error_type:message for grouping similar errors';
COMMENT ON COLUMN alert_digest.sample_error IS 'First error occurrence details as JSONB';
COMMENT ON COLUMN alert_digest.notified_at IS 'When digest email was sent (NULL = not yet notified)';
COMMENT ON FUNCTION aggregate_error IS 'Aggregate an error into the digest table for later notification';
```
  </action>
  <verify>Run migration: `cd maguey-pass-lounge && supabase db push`</verify>
  <done>Alert digest table and aggregate_error function created</done>
</task>

<task type="auto">
  <name>Task 2: Create send-error-digest edge function</name>
  <files>maguey-pass-lounge/supabase/functions/send-error-digest/index.ts</files>
  <action>
Create the error digest email sender:

```typescript
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";
import { createLogger, getRequestId } from "../_shared/logger.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

interface AlertDigestEntry {
  id: string;
  error_type: string;
  error_hash: string;
  first_occurrence: string;
  last_occurrence: string;
  occurrence_count: number;
  sample_error: {
    message: string;
    details?: Record<string, unknown>;
    timestamp: string;
  };
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response("ok", { headers: corsHeaders });
  }

  const requestId = getRequestId(req);
  const logger = createLogger(requestId);

  try {
    logger.info("Starting error digest processing");

    // Initialize Supabase client
    const supabase = createClient(
      Deno.env.get("SUPABASE_URL")!,
      Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!
    );

    // Fetch unnotified errors
    const { data: alerts, error: fetchError } = await supabase
      .from("alert_digest")
      .select("*")
      .is("notified_at", null)
      .order("occurrence_count", { ascending: false });

    if (fetchError) {
      throw new Error(`Failed to fetch alerts: ${fetchError.message}`);
    }

    if (!alerts || alerts.length === 0) {
      logger.info("No unnotified errors, skipping digest");
      return new Response(
        JSON.stringify({ message: "No errors to report", requestId }),
        { headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    logger.info("Found unnotified errors", { count: alerts.length });

    // Get owner email
    const ownerEmail = Deno.env.get("OWNER_EMAIL");
    if (!ownerEmail) {
      logger.warn("OWNER_EMAIL not configured, skipping digest");
      return new Response(
        JSON.stringify({ error: "OWNER_EMAIL not configured", requestId }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    // Build email content
    const totalErrors = alerts.reduce((sum, a) => sum + a.occurrence_count, 0);
    const errorTypes = [...new Set(alerts.map(a => a.error_type))];

    const emailHtml = buildDigestEmail(alerts as AlertDigestEntry[], totalErrors);

    // Send email via Resend
    const resendApiKey = Deno.env.get("RESEND_API_KEY");
    if (!resendApiKey) {
      logger.warn("RESEND_API_KEY not configured, skipping digest");
      return new Response(
        JSON.stringify({ error: "RESEND_API_KEY not configured", requestId }),
        { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
      );
    }

    const emailResponse = await fetch("https://api.resend.com/emails", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${resendApiKey}`,
      },
      body: JSON.stringify({
        from: "Maguey Nightclub <alerts@maguey.club>",
        to: [ownerEmail],
        subject: `[Alert] ${totalErrors} error${totalErrors > 1 ? 's' : ''} in the last 15 minutes`,
        html: emailHtml,
      }),
    });

    if (!emailResponse.ok) {
      const errorText = await emailResponse.text();
      throw new Error(`Resend API error: ${errorText}`);
    }

    logger.info("Digest email sent", { to: ownerEmail, errorCount: alerts.length });

    // Mark alerts as notified
    const alertIds = alerts.map(a => a.id);
    const { error: updateError } = await supabase
      .from("alert_digest")
      .update({ notified_at: new Date().toISOString() })
      .in("id", alertIds);

    if (updateError) {
      logger.warn("Failed to mark alerts as notified", { error: updateError.message });
    }

    return new Response(
      JSON.stringify({
        message: "Digest sent",
        requestId,
        alertCount: alerts.length,
        totalErrors,
      }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  } catch (error) {
    logger.error("Error sending digest", { error: error.message });
    return new Response(
      JSON.stringify({ error: error.message, requestId }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } }
    );
  }
});

function buildDigestEmail(alerts: AlertDigestEntry[], totalErrors: number): string {
  const now = new Date().toISOString();

  const alertRows = alerts.map(alert => `
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 12px; font-weight: bold; color: #c0392b;">${escapeHtml(alert.error_type)}</td>
      <td style="padding: 12px;">${alert.occurrence_count}x</td>
      <td style="padding: 12px; font-size: 12px; color: #666;">${escapeHtml(alert.sample_error.message || 'No message')}</td>
      <td style="padding: 12px; font-size: 12px; color: #888;">${new Date(alert.last_occurrence).toLocaleTimeString()}</td>
    </tr>
  `).join('');

  return `
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <title>Error Digest</title>
    </head>
    <body style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
      <h1 style="color: #c0392b; margin-bottom: 5px;">Error Digest</h1>
      <p style="color: #666; margin-top: 0;">Generated at ${now}</p>

      <div style="background: #fff3cd; border: 1px solid #ffc107; border-radius: 4px; padding: 15px; margin: 20px 0;">
        <strong>${totalErrors} total error${totalErrors > 1 ? 's' : ''}</strong> across ${alerts.length} unique issue${alerts.length > 1 ? 's' : ''}
      </div>

      <table style="width: 100%; border-collapse: collapse; margin-top: 20px;">
        <thead>
          <tr style="background: #f8f9fa;">
            <th style="padding: 12px; text-align: left;">Type</th>
            <th style="padding: 12px; text-align: left;">Count</th>
            <th style="padding: 12px; text-align: left;">Sample Message</th>
            <th style="padding: 12px; text-align: left;">Last Seen</th>
          </tr>
        </thead>
        <tbody>
          ${alertRows}
        </tbody>
      </table>

      <p style="margin-top: 30px; font-size: 12px; color: #888;">
        This is an automated alert from Maguey Nightclub systems.<br>
        Check the Supabase dashboard for full error details.
      </p>
    </body>
    </html>
  `;
}

function escapeHtml(text: string): string {
  return text
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&#039;');
}
```
  </action>
  <verify>Deploy function: `cd maguey-pass-lounge && supabase functions deploy send-error-digest`</verify>
  <done>Error digest edge function created and deployed</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Alert digest system including:
- alert_digest table for error aggregation
- aggregate_error() function for inserting/updating errors
- send-error-digest edge function for sending email digests
  </what-built>
  <how-to-verify>
1. **Verify table exists:**
   - Go to Supabase Dashboard -> Table Editor
   - Confirm `alert_digest` table exists with columns: id, error_type, error_hash, occurrence_count, etc.

2. **Test aggregation function:**
   - Run in SQL Editor:
   ```sql
   SELECT aggregate_error('test_error', 'This is a test error', '{"source": "manual_test"}'::jsonb);
   SELECT * FROM alert_digest WHERE error_type = 'test_error';
   ```
   - Confirm entry created with occurrence_count = 1
   - Run again and confirm occurrence_count = 2

3. **Test digest function:**
   - Call edge function:
   ```bash
   curl -X POST https://[PROJECT_REF].supabase.co/functions/v1/send-error-digest \
     -H "Authorization: Bearer [SERVICE_ROLE_KEY]"
   ```
   - Check OWNER_EMAIL inbox for digest email
   - Confirm alert_digest.notified_at is now set

4. **Configure pg_cron job (manual step):**
   - Go to Supabase Dashboard -> Database -> Extensions
   - Enable `pg_cron` and `pg_net` if not already
   - Go to SQL Editor and run:
   ```sql
   -- Store secrets in vault first
   INSERT INTO vault.secrets (name, secret)
   VALUES
     ('project_url', 'https://[PROJECT_REF].supabase.co'),
     ('service_role_key', '[SERVICE_ROLE_KEY]');

   -- Schedule digest every 15 minutes
   SELECT cron.schedule(
     'send-error-digest',
     '*/15 * * * *',
     $$
     SELECT net.http_post(
       url := (SELECT decrypted_secret FROM vault.decrypted_secrets WHERE name = 'project_url')
              || '/functions/v1/send-error-digest',
       headers := jsonb_build_object(
         'Content-Type', 'application/json',
         'Authorization', 'Bearer ' || (SELECT decrypted_secret FROM vault.decrypted_secrets WHERE name = 'service_role_key')
       ),
       body := '{}'::jsonb
     ) AS request_id;
     $$
   );
   ```
   - Verify job scheduled: `SELECT * FROM cron.job;`
  </how-to-verify>
  <resume-signal>Type "approved" once pg_cron is configured and test email received, or describe issues</resume-signal>
</task>

</tasks>

<verification>
- [ ] Migration runs successfully (alert_digest table created)
- [ ] aggregate_error function inserts/updates errors correctly
- [ ] send-error-digest function deployed
- [ ] Function fetches unnotified errors
- [ ] Function sends email via Resend
- [ ] Function marks alerts as notified after sending
- [ ] pg_cron extension enabled
- [ ] pg_cron job scheduled to run every 15 minutes
- [ ] Test email received by owner
</verification>

<success_criteria>
1. Calling aggregate_error() from any edge function logs the error
2. Multiple calls with same error_type + message increment count (no duplicate entries)
3. Every 15 minutes, owner receives digest email if errors exist
4. Email shows error types, counts, and sample messages
5. Notified errors don't appear in next digest
</success_criteria>

<output>
After completion, create `.planning/phases/06-infrastructure-monitoring/06-05-SUMMARY.md`
</output>
