---
phase: 02-email-reliability
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - maguey-pass-lounge/supabase/functions/process-email-queue/index.ts
autonomous: true

must_haves:
  truths:
    - "Queue processor fetches pending emails ready for retry"
    - "Emails are sent via Resend API with proper error handling"
    - "Failed sends schedule exponential backoff retry"
    - "Max attempts exhausted marks email as failed"
  artifacts:
    - path: "maguey-pass-lounge/supabase/functions/process-email-queue/index.ts"
      provides: "Email queue processing edge function"
      exports: ["serve"]
      min_lines: 80
  key_links:
    - from: "process-email-queue"
      to: "email_queue table"
      via: "supabase.from('email_queue')"
      pattern: "from\\('email_queue'\\)"
    - from: "process-email-queue"
      to: "Resend API"
      via: "fetch to api.resend.com"
      pattern: "api\\.resend\\.com/emails"
---

<objective>
Create edge function to process email queue with retries and exponential backoff.

Purpose: Background worker that sends queued emails with automatic retry on failure, ensuring emails eventually deliver even if Resend has temporary issues.
Output: Edge function that processes up to 10 pending emails per minute with exponential backoff on failures.
</objective>

<execution_context>
@/Users/luismiguel/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luismiguel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-email-reliability/02-CONTEXT.md
@.planning/phases/02-email-reliability/02-RESEARCH.md
@maguey-pass-lounge/supabase/functions/stripe-webhook/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create process-email-queue edge function</name>
  <files>maguey-pass-lounge/supabase/functions/process-email-queue/index.ts</files>
  <action>
Create the edge function following the pattern from 02-RESEARCH.md:

```typescript
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

function calculateNextRetryTime(attemptCount: number): Date {
  const baseDelayMs = 60 * 1000;  // 1 minute
  const maxDelayMs = 30 * 60 * 1000;  // 30 minutes
  const exponentialDelay = Math.min(baseDelayMs * Math.pow(2, attemptCount), maxDelayMs);
  const jitter = exponentialDelay * 0.1 * (Math.random() * 2 - 1);
  return new Date(Date.now() + exponentialDelay + jitter);
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response("ok", { headers: corsHeaders });
  }

  const supabase = createClient(
    Deno.env.get("SUPABASE_URL")!,
    Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!
  );

  const resendApiKey = Deno.env.get("RESEND_API_KEY");
  const fromEmail = Deno.env.get("EMAIL_FROM_ADDRESS") || "tickets@magueynightclub.com";
  const now = new Date().toISOString();

  if (!resendApiKey) {
    console.error("RESEND_API_KEY not configured");
    return new Response(JSON.stringify({ error: "Email service not configured" }), {
      status: 500,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }

  // Fetch pending emails ready for retry (limit batch size to avoid rate limits)
  const { data: pendingEmails, error: fetchError } = await supabase
    .from('email_queue')
    .select('*')
    .eq('status', 'pending')
    .lte('next_retry_at', now)
    .order('created_at', { ascending: true })
    .limit(10);

  if (fetchError) {
    console.error("Error fetching pending emails:", fetchError);
    return new Response(JSON.stringify({ error: fetchError.message }), {
      status: 500,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }

  if (!pendingEmails?.length) {
    return new Response(JSON.stringify({ processed: 0, message: "No pending emails" }), {
      status: 200,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }

  let processed = 0;
  let failed = 0;

  for (const email of pendingEmails) {
    // Mark as processing (prevents double-processing by concurrent invocations)
    const { error: lockError } = await supabase
      .from('email_queue')
      .update({ status: 'processing', updated_at: now })
      .eq('id', email.id)
      .eq('status', 'pending');  // Optimistic locking

    if (lockError) {
      console.warn(`Could not lock email ${email.id}, skipping:`, lockError);
      continue;
    }

    try {
      // Send via Resend API
      const response = await fetch("https://api.resend.com/emails", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${resendApiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          from: fromEmail,
          to: [email.recipient_email],
          subject: email.subject,
          html: email.html_body,
        }),
      });

      if (response.ok) {
        const { id: resendEmailId } = await response.json();

        // Mark as sent, store Resend ID for webhook correlation
        await supabase
          .from('email_queue')
          .update({
            status: 'sent',
            resend_email_id: resendEmailId,
            updated_at: new Date().toISOString(),
          })
          .eq('id', email.id);

        console.log(`Email ${email.id} sent successfully, Resend ID: ${resendEmailId}`);
        processed++;
      } else {
        const errorText = await response.text();
        throw new Error(`Resend API error ${response.status}: ${errorText}`);
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      const newAttemptCount = email.attempt_count + 1;

      console.error(`Email ${email.id} failed (attempt ${newAttemptCount}/${email.max_attempts}):`, errorMessage);

      if (newAttemptCount >= email.max_attempts) {
        // Permanently failed
        await supabase
          .from('email_queue')
          .update({
            status: 'failed',
            attempt_count: newAttemptCount,
            last_error: errorMessage,
            error_context: { final_failure: true, timestamp: new Date().toISOString() },
            updated_at: new Date().toISOString(),
          })
          .eq('id', email.id);

        console.error(`Email ${email.id} permanently failed after ${newAttemptCount} attempts`);
        failed++;

        // TODO: Notify owner of permanently failed email (Phase 2 can add this later)
      } else {
        // Schedule retry with exponential backoff
        const nextRetry = calculateNextRetryTime(newAttemptCount);

        await supabase
          .from('email_queue')
          .update({
            status: 'pending',
            attempt_count: newAttemptCount,
            next_retry_at: nextRetry.toISOString(),
            last_error: errorMessage,
            updated_at: new Date().toISOString(),
          })
          .eq('id', email.id);

        console.log(`Email ${email.id} scheduled for retry at ${nextRetry.toISOString()}`);
      }
    }
  }

  return new Response(JSON.stringify({ processed, failed, total: pendingEmails.length }), {
    status: 200,
    headers: { ...corsHeaders, "Content-Type": "application/json" },
  });
});
```

Key implementation details:
- Batch size of 10 to avoid Resend rate limits
- Optimistic locking with status='pending' check prevents double-processing
- Exponential backoff: 1min -> 2min -> 4min -> 8min -> 16min (capped at 30min)
- Jitter (+/- 10%) prevents thundering herd
- Max 5 attempts before permanent failure
- Stores resend_email_id for webhook correlation
  </action>
  <verify>
Check the function exists and has correct structure:
```bash
cat maguey-pass-lounge/supabase/functions/process-email-queue/index.ts
```
Verify it compiles with Deno syntax.
  </verify>
  <done>
Edge function exists at specified path with queue processing logic, Resend API integration, and exponential backoff retry.
  </done>
</task>

<task type="auto">
  <name>Task 2: Setup pg_cron job for queue processing</name>
  <files>maguey-pass-lounge/supabase/migrations/20260130100001_email_queue_cron.sql</files>
  <action>
Create migration to schedule the queue processor via pg_cron:

```sql
-- Enable pg_cron and pg_net extensions (if not already enabled)
CREATE EXTENSION IF NOT EXISTS pg_cron;
CREATE EXTENSION IF NOT EXISTS pg_net;

-- Store project URL and service role key in vault for secure access
-- Note: These need to be populated via Supabase dashboard or CLI
-- SELECT vault.create_secret('your-project-url', 'project_url');
-- SELECT vault.create_secret('your-service-role-key', 'service_role_key');

-- Schedule email queue processor to run every minute
-- Uses pg_net to call the edge function
SELECT cron.schedule(
  'process-email-queue',
  '* * * * *',  -- every minute
  $$
  SELECT net.http_post(
    url := current_setting('app.settings.project_url', true) || '/functions/v1/process-email-queue',
    headers := jsonb_build_object(
      'Content-Type', 'application/json',
      'Authorization', 'Bearer ' || current_setting('app.settings.service_role_key', true)
    ),
    body := '{}'::jsonb
  ) AS request_id;
  $$
);

-- Add comment explaining the job
COMMENT ON EXTENSION pg_cron IS 'Email queue processor runs every minute to send pending emails with retry logic';
```

Note: The actual secrets (project URL and service role key) need to be configured in Supabase. Create a simpler migration that just enables the extensions and documents the cron job setup. The actual cron job will be added via Supabase dashboard initially.

Simpler approach for migration:
```sql
-- Email Queue Cron Job Setup
-- This migration documents the pg_cron setup needed for email queue processing.
-- The actual cron job is configured via Supabase Dashboard -> Database -> Cron Jobs

-- Ensure pg_cron and pg_net are available (they are enabled by default in Supabase)
-- pg_cron: Schedule recurring jobs
-- pg_net: Make HTTP requests from database

-- Cron job to add (via Dashboard):
-- Name: process-email-queue
-- Schedule: * * * * * (every minute)
-- Command: See documentation in 02-RESEARCH.md

SELECT 'Email queue cron job should be configured via Supabase Dashboard' AS setup_note;
```
  </action>
  <verify>
Migration file exists. Note that the actual pg_cron configuration requires Supabase dashboard access (user_setup).
  </verify>
  <done>
Migration file documents pg_cron setup requirements. User will configure the cron job via Supabase Dashboard.
  </done>
</task>

</tasks>

<verification>
- [ ] process-email-queue/index.ts exists with correct logic
- [ ] Function fetches pending emails and sends via Resend
- [ ] Exponential backoff implemented correctly
- [ ] Max attempts triggers permanent failure status
- [ ] Migration documents pg_cron setup requirements
</verification>

<success_criteria>
- Edge function processes queue with retry logic
- Failed emails get rescheduled with exponential backoff
- Max attempts exhausted marks email as permanently failed
- pg_cron setup documented for user configuration
</success_criteria>

<output>
After completion, create `.planning/phases/02-email-reliability/02-02-SUMMARY.md`
</output>
