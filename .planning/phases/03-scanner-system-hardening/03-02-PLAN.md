---
phase: 03-scanner-system-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - maguey-gate-scanner/src/lib/offline-ticket-cache.ts
  - maguey-pass-lounge/supabase/migrations/20260130000000_add_scan_race_condition_handling.sql
autonomous: true

must_haves:
  truths:
    - "Ticket list can be downloaded for an event"
    - "Tickets can be validated locally when offline"
    - "Cache returns 'not_in_cache' for unknown tickets"
    - "Cache auto-syncs when event is selected"
    - "Old event caches are automatically cleaned up"
    - "Concurrent scans of same ticket result in only one success (race condition handled)"
    - "Offline sync uses first-scan-wins conflict resolution"
  artifacts:
    - path: "maguey-gate-scanner/src/lib/offline-ticket-cache.ts"
      provides: "Ticket caching service using Dexie.js"
      exports: ["syncTicketCache", "validateOffline", "getCacheStatus", "clearEventCache", "resolveOfflineConflicts"]
    - path: "maguey-pass-lounge/supabase/migrations/20260130000000_add_scan_race_condition_handling.sql"
      provides: "Database constraint for preventing duplicate successful scans"
      contains: "unique_successful_scan"
  key_links:
    - from: "offline-ticket-cache.ts"
      to: "supabase"
      via: "fetch tickets query"
      pattern: "supabase.*from.*tickets"
    - from: "offline-ticket-cache.ts"
      to: "Dexie"
      via: "IndexedDB storage"
      pattern: "extends Dexie"
    - from: "offline-queue-service.ts"
      to: "offline-ticket-cache.ts"
      via: "conflict resolution during sync"
      pattern: "resolveOfflineConflicts"
---

<objective>
Create offline ticket cache service for local validation when network is unavailable, with race condition handling for concurrent scans

Purpose: Scanner must validate tickets even without network. Caching the ticket list in IndexedDB allows local validation with immediate accept/reject feedback. Race conditions from concurrent scans (multiple devices or offline sync) must be handled gracefully with first-scan-wins resolution.

Output: offline-ticket-cache.ts service that syncs ticket data, validates scans locally, and handles concurrent scan race conditions
</objective>

<execution_context>
@/Users/luismiguel/.claude/get-shit-done/workflows/execute-plan.md
@/Users/luismiguel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-scanner-system-hardening/03-CONTEXT.md
@.planning/phases/03-scanner-system-hardening/03-RESEARCH.md

@maguey-gate-scanner/src/lib/offline-queue-service.ts
@maguey-gate-scanner/src/lib/simple-scanner.ts
@maguey-gate-scanner/src/lib/supabase.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create database migration for race condition handling</name>
  <files>maguey-pass-lounge/supabase/migrations/20260130000000_add_scan_race_condition_handling.sql</files>
  <action>
Create migration to add database-level protection against concurrent scan race conditions:

```sql
-- Migration: Add race condition handling for concurrent ticket scans
-- This prevents two scanners from successfully scanning the same ticket simultaneously

-- 1. Add unique constraint on scan_logs for successful scans
-- This ensures only one successful scan record can exist per ticket
-- The constraint only applies to successful scans (not failed attempts)

-- First, add a column to track scan success (if not exists)
DO $$
BEGIN
  IF NOT EXISTS (
    SELECT 1 FROM information_schema.columns
    WHERE table_name = 'scan_logs' AND column_name = 'scan_success'
  ) THEN
    ALTER TABLE scan_logs ADD COLUMN scan_success BOOLEAN DEFAULT true;
  END IF;
END $$;

-- Create partial unique index: only one successful scan per ticket
CREATE UNIQUE INDEX IF NOT EXISTS unique_successful_scan
ON scan_logs (ticket_id)
WHERE scan_success = true;

-- 2. Create function for atomic scan with race condition handling
CREATE OR REPLACE FUNCTION scan_ticket_atomic(
  p_ticket_id UUID,
  p_scanned_by UUID,
  p_device_id TEXT DEFAULT NULL,
  p_scan_method TEXT DEFAULT 'qr'
) RETURNS TABLE (
  success BOOLEAN,
  already_scanned BOOLEAN,
  scanned_at TIMESTAMPTZ,
  scanned_by UUID,
  error_message TEXT
) AS $$
DECLARE
  v_ticket RECORD;
  v_existing_scan RECORD;
BEGIN
  -- Lock the ticket row to prevent concurrent modifications
  SELECT * INTO v_ticket
  FROM tickets
  WHERE id = p_ticket_id
  FOR UPDATE NOWAIT;

  IF NOT FOUND THEN
    RETURN QUERY SELECT false, false, NULL::TIMESTAMPTZ, NULL::UUID, 'Ticket not found'::TEXT;
    RETURN;
  END IF;

  -- Check if already scanned
  IF v_ticket.is_used = true OR v_ticket.status = 'scanned' THEN
    -- Return existing scan info
    SELECT sl.scanned_at, sl.scanned_by INTO v_existing_scan
    FROM scan_logs sl
    WHERE sl.ticket_id = p_ticket_id AND sl.scan_success = true
    LIMIT 1;

    RETURN QUERY SELECT
      false,
      true,
      COALESCE(v_existing_scan.scanned_at, v_ticket.scanned_at),
      COALESCE(v_existing_scan.scanned_by, v_ticket.scanned_by),
      'Ticket already scanned'::TEXT;
    RETURN;
  END IF;

  -- Attempt to mark as scanned (atomic update)
  UPDATE tickets
  SET
    is_used = true,
    status = 'scanned',
    scanned_at = NOW(),
    scanned_by = p_scanned_by,
    updated_at = NOW()
  WHERE id = p_ticket_id
    AND is_used = false
    AND (status IS NULL OR status != 'scanned');

  IF NOT FOUND THEN
    -- Another transaction beat us - race condition handled
    RETURN QUERY SELECT false, true, NOW(), NULL::UUID, 'Concurrent scan detected'::TEXT;
    RETURN;
  END IF;

  -- Log the successful scan
  INSERT INTO scan_logs (
    ticket_id,
    scanned_by,
    scanned_at,
    scan_method,
    device_id,
    scan_success
  ) VALUES (
    p_ticket_id,
    p_scanned_by,
    NOW(),
    p_scan_method,
    p_device_id,
    true
  )
  ON CONFLICT ON CONSTRAINT unique_successful_scan DO NOTHING;

  RETURN QUERY SELECT true, false, NOW(), p_scanned_by, NULL::TEXT;

EXCEPTION
  WHEN lock_not_available THEN
    -- Another transaction has the lock - likely concurrent scan
    RETURN QUERY SELECT false, false, NULL::TIMESTAMPTZ, NULL::UUID, 'Ticket being processed by another scanner'::TEXT;
  WHEN unique_violation THEN
    -- Unique constraint caught the race condition
    RETURN QUERY SELECT false, true, NOW(), NULL::UUID, 'Concurrent scan - another device scanned first'::TEXT;
END;
$$ LANGUAGE plpgsql;

-- 3. Create function for offline sync with first-scan-wins resolution
CREATE OR REPLACE FUNCTION sync_offline_scan(
  p_ticket_id UUID,
  p_scanned_by UUID,
  p_scanned_at TIMESTAMPTZ,
  p_device_id TEXT DEFAULT NULL
) RETURNS TABLE (
  success BOOLEAN,
  conflict_resolved BOOLEAN,
  winner_device TEXT,
  winner_time TIMESTAMPTZ
) AS $$
DECLARE
  v_ticket RECORD;
  v_existing_scan RECORD;
BEGIN
  -- Lock the ticket
  SELECT * INTO v_ticket
  FROM tickets
  WHERE id = p_ticket_id
  FOR UPDATE;

  IF NOT FOUND THEN
    RETURN QUERY SELECT false, false, NULL::TEXT, NULL::TIMESTAMPTZ;
    RETURN;
  END IF;

  -- Check if already scanned
  IF v_ticket.is_used = true OR v_ticket.status = 'scanned' THEN
    -- Get existing scan details
    SELECT sl.scanned_at, sl.device_id INTO v_existing_scan
    FROM scan_logs sl
    WHERE sl.ticket_id = p_ticket_id AND sl.scan_success = true
    LIMIT 1;

    -- First-scan-wins: compare timestamps
    IF v_existing_scan.scanned_at IS NOT NULL AND p_scanned_at < v_existing_scan.scanned_at THEN
      -- Offline scan was first - update to reflect true first scanner
      -- (This is rare but handles the edge case correctly)
      UPDATE tickets
      SET
        scanned_at = p_scanned_at,
        scanned_by = p_scanned_by,
        updated_at = NOW()
      WHERE id = p_ticket_id;

      -- Update scan log
      UPDATE scan_logs
      SET
        scanned_at = p_scanned_at,
        scanned_by = p_scanned_by,
        device_id = p_device_id
      WHERE ticket_id = p_ticket_id AND scan_success = true;

      RETURN QUERY SELECT true, true, p_device_id, p_scanned_at;
    ELSE
      -- Existing scan was first - offline scan loses
      RETURN QUERY SELECT false, true, v_existing_scan.device_id, v_existing_scan.scanned_at;
    END IF;
    RETURN;
  END IF;

  -- Not yet scanned - apply offline scan
  UPDATE tickets
  SET
    is_used = true,
    status = 'scanned',
    scanned_at = p_scanned_at,
    scanned_by = p_scanned_by,
    updated_at = NOW()
  WHERE id = p_ticket_id;

  INSERT INTO scan_logs (
    ticket_id,
    scanned_by,
    scanned_at,
    scan_method,
    device_id,
    scan_success
  ) VALUES (
    p_ticket_id,
    p_scanned_by,
    p_scanned_at,
    'offline_sync',
    p_device_id,
    true
  )
  ON CONFLICT ON CONSTRAINT unique_successful_scan DO NOTHING;

  RETURN QUERY SELECT true, false, p_device_id, p_scanned_at;
END;
$$ LANGUAGE plpgsql;

-- Add comment explaining the race condition handling
COMMENT ON FUNCTION scan_ticket_atomic IS 'Atomic ticket scan with row-level locking to prevent race conditions from concurrent scanners';
COMMENT ON FUNCTION sync_offline_scan IS 'Sync offline scans with first-scan-wins conflict resolution based on timestamps';
COMMENT ON INDEX unique_successful_scan IS 'Ensures only one successful scan per ticket - database-level race condition protection';
```
  </action>
  <verify>Migration file created: `test -f maguey-pass-lounge/supabase/migrations/20260130000000_add_scan_race_condition_handling.sql && echo "exists"`</verify>
  <done>Database migration adds atomic scan function and unique constraint for race condition prevention</done>
</task>

<task type="auto">
  <name>Task 2: Create Dexie database schema and core cache functions</name>
  <files>maguey-gate-scanner/src/lib/offline-ticket-cache.ts</files>
  <action>
Create offline-ticket-cache.ts following the pattern from offline-queue-service.ts:

**1. Imports:**
```typescript
import Dexie, { Table } from 'dexie';
import { supabase } from './supabase';
```

**2. Type definitions:**
```typescript
export interface CachedTicket {
  ticketId: string;       // Primary key
  eventId: string;
  qrToken: string;        // For lookup during scan
  qrSignature?: string;
  status: 'valid' | 'scanned';
  guestName?: string;
  ticketType: string;
  scannedAt?: string;
  scannedBy?: string;     // User ID who scanned
  scannedByName?: string; // Display name for UI
  syncedAt: string;       // When this cache entry was updated
}

export interface CacheMetadata {
  eventId: string;        // Primary key
  eventName: string;
  lastSyncAt: string;
  ticketCount: number;
  totalCapacity: number;
  scannedCount: number;
}

export interface OfflineScanRecord {
  id: string;             // Auto-generated
  ticketId: string;
  qrToken: string;
  scannedAt: string;      // Timestamp when scanned offline
  scannedBy?: string;
  deviceId: string;
  syncStatus: 'pending' | 'synced' | 'conflict' | 'failed';
  conflictResolution?: {
    winner: 'local' | 'remote';
    winnerTime: string;
    winnerDevice: string;
  };
}
```

**3. Dexie database class:**
```typescript
class TicketCacheDatabase extends Dexie {
  cachedTickets!: Table<CachedTicket, string>;
  cacheMetadata!: Table<CacheMetadata, string>;
  offlineScans!: Table<OfflineScanRecord, string>;

  constructor() {
    super('TicketCacheDatabase');
    this.version(1).stores({
      cachedTickets: 'ticketId, eventId, qrToken, status',
      cacheMetadata: 'eventId',
      offlineScans: '++id, ticketId, syncStatus, scannedAt',
    });
  }
}

const db = new TicketCacheDatabase();

// Get device ID for conflict resolution tracking
function getDeviceId(): string {
  let deviceId = localStorage.getItem('scanner_device_id');
  if (!deviceId) {
    deviceId = `device_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    localStorage.setItem('scanner_device_id', deviceId);
  }
  return deviceId;
}
```

**4. syncTicketCache - Download tickets for an event:**
```typescript
export async function syncTicketCache(eventId: string): Promise<{
  success: boolean;
  ticketCount: number;
  error?: string;
}> {
  try {
    // Fetch event info
    const { data: eventData, error: eventError } = await supabase
      .from('events')
      .select('id, name')
      .eq('id', eventId)
      .single();

    if (eventError) throw eventError;

    // Fetch all tickets for this event
    const { data: tickets, error: ticketsError } = await supabase
      .from('tickets')
      .select(`
        id,
        ticket_id,
        qr_code_data,
        status,
        is_used,
        guest_name,
        ticket_type,
        scanned_at,
        scanned_by
      `)
      .eq('event_id', eventId);

    if (ticketsError) throw ticketsError;

    // Get scanned count
    const scannedCount = (tickets || []).filter(t => t.is_used || t.status === 'scanned').length;

    // Clear existing cache for this event
    await db.cachedTickets.where('eventId').equals(eventId).delete();

    // Insert new cache entries
    const now = new Date().toISOString();
    const cacheEntries: CachedTicket[] = (tickets || []).map(t => ({
      ticketId: t.id,
      eventId,
      qrToken: t.qr_code_data || t.ticket_id,
      status: (t.is_used || t.status === 'scanned') ? 'scanned' : 'valid',
      guestName: t.guest_name || undefined,
      ticketType: t.ticket_type || 'General',
      scannedAt: t.scanned_at || undefined,
      scannedBy: t.scanned_by || undefined,
      syncedAt: now,
    }));

    await db.cachedTickets.bulkPut(cacheEntries);

    // Update metadata
    await db.cacheMetadata.put({
      eventId,
      eventName: eventData.name,
      lastSyncAt: now,
      ticketCount: cacheEntries.length,
      totalCapacity: cacheEntries.length,
      scannedCount,
    });

    // Notify listeners
    const metadata = await db.cacheMetadata.get(eventId);
    if (metadata) notifyListeners(eventId, metadata);

    console.log('[offline-ticket-cache] Synced', cacheEntries.length, 'tickets for event', eventId);
    return { success: true, ticketCount: cacheEntries.length };
  } catch (error: any) {
    console.error('[offline-ticket-cache] Sync failed:', error);
    return { success: false, ticketCount: 0, error: error.message };
  }
}
```

**5. validateOffline - Check ticket against cache:**
```typescript
export async function validateOffline(qrToken: string, eventId?: string): Promise<{
  status: 'valid' | 'scanned' | 'not_in_cache' | 'wrong_event';
  ticket?: CachedTicket;
}> {
  // Try to find by qrToken
  const ticket = await db.cachedTickets.where('qrToken').equals(qrToken).first();

  if (!ticket) {
    return { status: 'not_in_cache' };
  }

  // Check event match if eventId filter is provided
  if (eventId && ticket.eventId !== eventId) {
    return { status: 'wrong_event', ticket };
  }

  return { status: ticket.status, ticket };
}
```

**6. markAsScannedOffline - Update local cache and record for sync:**
```typescript
export async function markAsScannedOffline(
  ticketId: string,
  scannedBy?: string
): Promise<boolean> {
  try {
    const now = new Date().toISOString();
    const ticket = await db.cachedTickets.get(ticketId);

    if (!ticket) return false;

    // Update local cache
    await db.cachedTickets.update(ticketId, {
      status: 'scanned',
      scannedAt: now,
      scannedBy,
      syncedAt: now,
    });

    // Record offline scan for later sync with conflict resolution
    await db.offlineScans.add({
      ticketId,
      qrToken: ticket.qrToken,
      scannedAt: now,
      scannedBy,
      deviceId: getDeviceId(),
      syncStatus: 'pending',
    });

    // Update scanned count in metadata
    const metadata = await db.cacheMetadata.get(ticket.eventId);
    if (metadata) {
      await db.cacheMetadata.update(ticket.eventId, {
        scannedCount: metadata.scannedCount + 1,
      });
      notifyListeners(ticket.eventId, { ...metadata, scannedCount: metadata.scannedCount + 1 });
    }

    return true;
  } catch (error) {
    console.error('[offline-ticket-cache] Failed to mark as scanned:', error);
    return false;
  }
}
```
  </action>
  <verify>File created: `test -f maguey-gate-scanner/src/lib/offline-ticket-cache.ts && echo "exists"`</verify>
  <done>Dexie database schema created with cachedTickets, cacheMetadata, and offlineScans tables</done>
</task>

<task type="auto">
  <name>Task 3: Implement conflict resolution and remaining cache functions</name>
  <files>maguey-gate-scanner/src/lib/offline-ticket-cache.ts</files>
  <action>
Add conflict resolution and remaining utility functions to offline-ticket-cache.ts:

**1. resolveOfflineConflicts - Sync pending offline scans with first-scan-wins:**
```typescript
export async function resolveOfflineConflicts(): Promise<{
  synced: number;
  conflicts: number;
  failed: number;
  results: Array<{
    ticketId: string;
    result: 'synced' | 'conflict_won' | 'conflict_lost' | 'failed';
    message?: string;
  }>;
}> {
  const pendingScans = await db.offlineScans
    .where('syncStatus')
    .equals('pending')
    .toArray();

  const results: Array<{
    ticketId: string;
    result: 'synced' | 'conflict_won' | 'conflict_lost' | 'failed';
    message?: string;
  }> = [];

  let synced = 0;
  let conflicts = 0;
  let failed = 0;

  for (const scan of pendingScans) {
    try {
      // Call the database function for first-scan-wins resolution
      const { data, error } = await supabase.rpc('sync_offline_scan', {
        p_ticket_id: scan.ticketId,
        p_scanned_by: scan.scannedBy || null,
        p_scanned_at: scan.scannedAt,
        p_device_id: scan.deviceId,
      });

      if (error) throw error;

      const result = data?.[0];

      if (result?.success) {
        if (result.conflict_resolved) {
          // We won the conflict - our scan was earlier
          await db.offlineScans.update(scan.id!, {
            syncStatus: 'synced',
            conflictResolution: {
              winner: 'local',
              winnerTime: scan.scannedAt,
              winnerDevice: scan.deviceId,
            },
          });
          results.push({ ticketId: scan.ticketId, result: 'conflict_won' });
          conflicts++;
        } else {
          // Normal sync - no conflict
          await db.offlineScans.update(scan.id!, { syncStatus: 'synced' });
          results.push({ ticketId: scan.ticketId, result: 'synced' });
          synced++;
        }
      } else if (result?.conflict_resolved) {
        // We lost the conflict - another scan was earlier
        await db.offlineScans.update(scan.id!, {
          syncStatus: 'conflict',
          conflictResolution: {
            winner: 'remote',
            winnerTime: result.winner_time,
            winnerDevice: result.winner_device || 'unknown',
          },
        });
        results.push({
          ticketId: scan.ticketId,
          result: 'conflict_lost',
          message: `Another device scanned first at ${new Date(result.winner_time).toLocaleTimeString()}`,
        });
        conflicts++;
      } else {
        // Failed for other reason
        await db.offlineScans.update(scan.id!, { syncStatus: 'failed' });
        results.push({ ticketId: scan.ticketId, result: 'failed', message: 'Sync failed' });
        failed++;
      }
    } catch (error: any) {
      console.error('[offline-ticket-cache] Conflict resolution failed for', scan.ticketId, error);
      await db.offlineScans.update(scan.id!, { syncStatus: 'failed' });
      results.push({ ticketId: scan.ticketId, result: 'failed', message: error.message });
      failed++;
    }
  }

  console.log('[offline-ticket-cache] Resolved:', { synced, conflicts, failed });
  return { synced, conflicts, failed, results };
}
```

**2. getPendingOfflineScans - For UI display:**
```typescript
export async function getPendingOfflineScans(): Promise<OfflineScanRecord[]> {
  return await db.offlineScans
    .where('syncStatus')
    .equals('pending')
    .toArray();
}

export async function getConflictedScans(): Promise<OfflineScanRecord[]> {
  return await db.offlineScans
    .where('syncStatus')
    .equals('conflict')
    .toArray();
}
```

**3. getCacheStatus and related utilities:**
```typescript
export async function getCacheStatus(eventId: string): Promise<CacheMetadata | null> {
  return await db.cacheMetadata.get(eventId);
}

export async function getAllCachedEvents(): Promise<CacheMetadata[]> {
  return await db.cacheMetadata.toArray();
}

export async function getCheckedInCount(eventId: string): Promise<{
  checkedIn: number;
  total: number;
}> {
  const metadata = await db.cacheMetadata.get(eventId);
  if (!metadata) {
    return { checkedIn: 0, total: 0 };
  }
  return {
    checkedIn: metadata.scannedCount,
    total: metadata.ticketCount,
  };
}
```

**4. Cache cleanup functions:**
```typescript
export async function clearEventCache(eventId: string): Promise<void> {
  await db.cachedTickets.where('eventId').equals(eventId).delete();
  await db.cacheMetadata.delete(eventId);
  console.log('[offline-ticket-cache] Cleared cache for event', eventId);
}

// Clear caches older than 24 hours per context decision
export async function clearOldCaches(): Promise<number> {
  const oneDayAgo = new Date();
  oneDayAgo.setHours(oneDayAgo.getHours() - 24);
  const cutoff = oneDayAgo.toISOString();

  const oldEvents = await db.cacheMetadata
    .filter(m => m.lastSyncAt < cutoff)
    .toArray();

  for (const event of oldEvents) {
    await clearEventCache(event.eventId);
  }

  // Also clear old synced offline scans (keep conflicts for review)
  await db.offlineScans
    .where('syncStatus')
    .equals('synced')
    .filter(s => s.scannedAt < cutoff)
    .delete();

  console.log('[offline-ticket-cache] Cleared', oldEvents.length, 'old event caches');
  return oldEvents.length;
}
```

**5. Auto-sync and listener pattern:**
```typescript
const CACHE_REFRESH_INTERVAL_MS = 5 * 60 * 1000; // 5 minutes

export async function ensureCacheIsFresh(eventId: string): Promise<{
  status: 'fresh' | 'refreshed' | 'failed';
  ticketCount: number;
}> {
  const metadata = await db.cacheMetadata.get(eventId);

  if (metadata) {
    const lastSync = new Date(metadata.lastSyncAt).getTime();
    const now = Date.now();

    if (now - lastSync < CACHE_REFRESH_INTERVAL_MS) {
      return { status: 'fresh', ticketCount: metadata.ticketCount };
    }
  }

  if (!navigator.onLine) {
    if (metadata) {
      return { status: 'fresh', ticketCount: metadata.ticketCount };
    }
    return { status: 'failed', ticketCount: 0 };
  }

  const result = await syncTicketCache(eventId);
  return {
    status: result.success ? 'refreshed' : 'failed',
    ticketCount: result.ticketCount,
  };
}

// Listener pattern for real-time UI updates
type CacheListener = (eventId: string, metadata: CacheMetadata) => void;
const listeners: CacheListener[] = [];

export function subscribeToCacheUpdates(listener: CacheListener): () => void {
  listeners.push(listener);
  return () => {
    const index = listeners.indexOf(listener);
    if (index > -1) listeners.splice(index, 1);
  };
}

function notifyListeners(eventId: string, metadata: CacheMetadata) {
  listeners.forEach(l => l(eventId, metadata));
}
```
  </action>
  <verify>All exports present: `grep -E "export (async )?function" maguey-gate-scanner/src/lib/offline-ticket-cache.ts | wc -l` should show 10+ functions</verify>
  <done>All cache functions implemented including resolveOfflineConflicts for first-scan-wins conflict resolution</done>
</task>

</tasks>

<verification>
1. Build completes without errors
2. Database migration creates scan_ticket_atomic and sync_offline_scan functions
3. Unique constraint unique_successful_scan prevents duplicate successful scans
4. offline-ticket-cache.ts exports all required functions including resolveOfflineConflicts
5. Offline scans are recorded with timestamp for first-scan-wins resolution
6. Conflict resolution correctly identifies winner based on earliest timestamp
</verification>

<success_criteria>
1. Database prevents concurrent successful scans with unique constraint
2. scan_ticket_atomic function handles row-level locking for concurrent online scans
3. sync_offline_scan function implements first-scan-wins based on timestamps
4. syncTicketCache downloads and stores ticket list for an event
5. validateOffline returns 'valid', 'scanned', or 'not_in_cache'
6. markAsScannedOffline records scan with timestamp for conflict resolution
7. resolveOfflineConflicts syncs pending scans and reports conflict outcomes
8. clearOldCaches removes caches older than 24 hours
</success_criteria>

<output>
After completion, create `.planning/phases/03-scanner-system-hardening/03-02-SUMMARY.md`
</output>
